{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f403fbe",
   "metadata": {},
   "source": [
    "# Basic Convolutional Neural Network for classifying CIFAR-10 dataset\n",
    "\n",
    "Written by: Joshua Chen\n",
    "\n",
    "This Python notebook serves as a quick reference or simple tutorial on the CNN training pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8261fc",
   "metadata": {},
   "source": [
    "## Import all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3211256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531d3560",
   "metadata": {},
   "source": [
    "## Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba1381e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "LR = 1e-3\n",
    "MODEL_SAVE_PATH = './Models'\n",
    "\n",
    "if not os.path.exists(MODEL_SAVE_PATH):\n",
    "    os.mkdir(MODEL_SAVE_PATH)\n",
    "    \n",
    "# Define image transforms and/or augmentations:\n",
    "transform = transforms.Compose([transforms.Resize(32), \n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aa7782",
   "metadata": {},
   "source": [
    "## General Deep CV Neural Network Training Pipeline:\n",
    "\n",
    "1) Import and normalize the dataset. \n",
    "\n",
    "2) Define neural network and import it.\n",
    "\n",
    "3) Define Loss function and optimizer.\n",
    "\n",
    "4) Train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d52b572c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Import and Normalize Dataset:\n",
    "training = torchvision.datasets.CIFAR10(root='./cifar10Data', train=True, download=True, transform=transform)\n",
    "trainLoader = DataLoader(training, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "testing = torchvision.datasets.CIFAR10(root='./cifar10Data', train=False, download=True, transform=transform)\n",
    "testLoader = DataLoader(testing, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e526e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to ensure GPU is available:\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caf76ed",
   "metadata": {},
   "source": [
    "## Import Custom CNN or use an existing architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c923bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Convolutional Neural Network:\n",
    "import cnn_model\n",
    "net = cnn_model.ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0519bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Premade Architecture if not using custom CNN:\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "weights = ResNet50_Weights.DEFAULT\n",
    "net = resnet50(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342667a5",
   "metadata": {},
   "source": [
    "## Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbd5a466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Loss Function and Optimizer:\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "loss = nn.CrossEntropyLoss() # Softmax Loss\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9) # Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fdbf3d",
   "metadata": {},
   "source": [
    "## Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e72117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Train and Test functions:\n",
    "def train(trainLoader, net, loss_fn, optimizer):\n",
    "    size = len(trainLoader.dataset)\n",
    "    net.train()\n",
    "    for batch, (X,y) in enumerate(trainLoader):\n",
    "        X, y = X.to(device), y.to(device) # Send training data to GPU\n",
    "        \n",
    "        # Compute Loss:\n",
    "        pred = net(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1)*len(X)\n",
    "            print(f\"Loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "            \n",
    "def test(testLoader, net, loss_fn):\n",
    "    size = len(testLoader.dataset)\n",
    "    num_batches = len(testLoader)\n",
    "    net.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in testLoader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = net(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches # Average Test Loss\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d1c127e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "---------------------------------\n",
      "Loss: 13.725882 [   64/50000]\n",
      "Loss: 6.597033 [ 6464/50000]\n",
      "Loss: 5.677573 [12864/50000]\n",
      "Loss: 3.349605 [19264/50000]\n",
      "Loss: 2.068901 [25664/50000]\n",
      "Loss: 1.505867 [32064/50000]\n",
      "Loss: 1.540960 [38464/50000]\n",
      "Loss: 1.378218 [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.109370 \n",
      "\n",
      "Epoch 2\n",
      "---------------------------------\n",
      "Loss: 0.943730 [   64/50000]\n",
      "Loss: 0.984301 [ 6464/50000]\n",
      "Loss: 1.069256 [12864/50000]\n",
      "Loss: 0.974396 [19264/50000]\n",
      "Loss: 1.026370 [25664/50000]\n",
      "Loss: 0.862955 [32064/50000]\n",
      "Loss: 1.395810 [38464/50000]\n",
      "Loss: 0.830054 [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.790166 \n",
      "\n",
      "Epoch 3\n",
      "---------------------------------\n",
      "Loss: 0.646730 [   64/50000]\n",
      "Loss: 0.818648 [ 6464/50000]\n",
      "Loss: 0.504553 [12864/50000]\n",
      "Loss: 0.705039 [19264/50000]\n",
      "Loss: 0.685125 [25664/50000]\n",
      "Loss: 0.751926 [32064/50000]\n",
      "Loss: 0.556361 [38464/50000]\n",
      "Loss: 0.720148 [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.685712 \n",
      "\n",
      "Epoch 4\n",
      "---------------------------------\n",
      "Loss: 0.490421 [   64/50000]\n",
      "Loss: 0.475917 [ 6464/50000]\n",
      "Loss: 0.498290 [12864/50000]\n",
      "Loss: 0.491171 [19264/50000]\n",
      "Loss: 0.590765 [25664/50000]\n",
      "Loss: 0.557979 [32064/50000]\n",
      "Loss: 0.403363 [38464/50000]\n",
      "Loss: 0.394667 [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.678779 \n",
      "\n",
      "Epoch 5\n",
      "---------------------------------\n",
      "Loss: 0.286735 [   64/50000]\n",
      "Loss: 0.380583 [ 6464/50000]\n",
      "Loss: 0.420395 [12864/50000]\n",
      "Loss: 0.553566 [19264/50000]\n",
      "Loss: 0.513174 [25664/50000]\n",
      "Loss: 0.237423 [32064/50000]\n",
      "Loss: 0.301956 [38464/50000]\n",
      "Loss: 0.434172 [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.610063 \n",
      "\n",
      "Epoch 6\n",
      "---------------------------------\n",
      "Loss: 0.254539 [   64/50000]\n",
      "Loss: 0.515187 [ 6464/50000]\n",
      "Loss: 0.290857 [12864/50000]\n",
      "Loss: 0.170088 [19264/50000]\n",
      "Loss: 0.445076 [25664/50000]\n",
      "Loss: 0.266651 [32064/50000]\n",
      "Loss: 0.354868 [38464/50000]\n",
      "Loss: 0.352367 [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.606736 \n",
      "\n",
      "Epoch 7\n",
      "---------------------------------\n",
      "Loss: 0.244531 [   64/50000]\n",
      "Loss: 0.127985 [ 6464/50000]\n",
      "Loss: 0.148698 [12864/50000]\n",
      "Loss: 0.354755 [19264/50000]\n",
      "Loss: 0.361824 [25664/50000]\n",
      "Loss: 0.263407 [32064/50000]\n",
      "Loss: 0.350406 [38464/50000]\n",
      "Loss: 0.405424 [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.613439 \n",
      "\n",
      "Epoch 8\n",
      "---------------------------------\n",
      "Loss: 0.167704 [   64/50000]\n",
      "Loss: 0.183041 [ 6464/50000]\n",
      "Loss: 0.090435 [12864/50000]\n",
      "Loss: 0.213020 [19264/50000]\n",
      "Loss: 0.245346 [25664/50000]\n",
      "Loss: 0.163729 [32064/50000]\n",
      "Loss: 0.207176 [38464/50000]\n",
      "Loss: 0.228862 [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.617083 \n",
      "\n",
      "Epoch 9\n",
      "---------------------------------\n",
      "Loss: 0.144512 [   64/50000]\n",
      "Loss: 0.079285 [ 6464/50000]\n",
      "Loss: 0.282059 [12864/50000]\n",
      "Loss: 0.391587 [19264/50000]\n",
      "Loss: 0.061911 [25664/50000]\n",
      "Loss: 0.285452 [32064/50000]\n",
      "Loss: 0.164342 [38464/50000]\n",
      "Loss: 0.243654 [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.686616 \n",
      "\n",
      "Epoch 10\n",
      "---------------------------------\n",
      "Loss: 0.231127 [   64/50000]\n",
      "Loss: 0.084401 [ 6464/50000]\n",
      "Loss: 0.238010 [12864/50000]\n",
      "Loss: 0.241295 [19264/50000]\n",
      "Loss: 0.113988 [25664/50000]\n",
      "Loss: 0.041971 [32064/50000]\n",
      "Loss: 0.146534 [38464/50000]\n",
      "Loss: 0.092784 [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.727745 \n",
      "\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    print(f\"Epoch {i+1}\\n---------------------------------\")\n",
    "    train(trainLoader, net, loss, optimizer)\n",
    "    test(testLoader, net, loss)\n",
    "print(\"Finished Training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e00e1a6",
   "metadata": {},
   "source": [
    "## Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "310115bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, MODEL_SAVE_PATH + '/resnet50cifar10.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
